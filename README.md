# LLM-Based Python Script Parameterizer

A local [Streamlit](https://streamlit.io/) app that uses OpenAI's GPT model to analyze and transform a Python script into a parameterized version using a YAML configuration file. It includes:

* GPT-powered Python script transformation
* YAML config file generation
* Custom instructions
* Logging, output saving, error handling

---

## 📁 Project Structure

```
llm_parameterizer/
├── app.py                  # Streamlit app (main file)
├── logs/
│   └── llm_app.log         # Application log file
├── output/
│   ├── modified_script.py  # Output Python script
│   └── config.yaml         # Output YAML config
├── requirements.txt        # Python dependencies
├── README.md               # Project documentation
```

---

## 🧠 Features

* Upload or use sample Python scripts
* Customize instructions to LLM
* Supports both GPT-3.5 and GPT-4
* Extracts and downloads YAML parameters
* Autogenerated script headers with metadata
* Logging to track processing activity

---

## 🚀 Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/llm-parameterizer.git
cd llm-parameterizer
```

### 2. Set up a Python environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Set up OpenAI API access

* Create an account at [platform.openai.com](https://platform.openai.com/signup)
* Go to [API Keys](https://platform.openai.com/account/api-keys) and generate a new key
* Create a `.env` file (optional) or enter the key manually in the app

**Optional: Set API Key as an environment variable**

```bash
export OPENAI_API_KEY=your-openai-key
```

---

## 💳 OpenAI Billing Setup

> ⚠️ Using GPT-4 requires a paid OpenAI plan.

1. Go to [https://platform.openai.com/account/billing](https://platform.openai.com/account/billing)
2. Add a payment method
3. Enable usage for GPT-4 if not already available

---

## 🖥️ Run the App

```bash
streamlit run app.py
```

Then open: `http://localhost:8501`

---

## 📝 Example Use Case

### Original script:

```python
def connect_and_download(url):
    import requests
    response = requests.get(url)
    return response.json()
```

### Output (transformed by LLM):

#### Modified script

```python
# Author: Pavan Kotapati
# Created on: 2025-08-06
# Last updated: 2025-08-06
# Description: Parameterized using OpenAI LLM

import requests
import yaml

def connect_and_download(url, timeout):
    response = requests.get(url, timeout=timeout)
    return response.json()

if __name__ == "__main__":
    with open("config.yaml") as f:
        config = yaml.safe_load(f)
    data = connect_and_download(config["url"], config["timeout"])
    print(data)
```

#### YAML config

```yaml
url: "https://api.example.com/data"
timeout: 10
```

---

## ⚠️ Troubleshooting

* **Error: Could not parse code blocks**: Ensure your prompt uses the correct format (`python and `yaml).
* **Model not accessible**: Make sure your billing is active and GPT-4 access is enabled.
* **Rate limits**: OpenAI may throttle requests if you exceed quota.

---

## 📌 Notes on `openai` Migration (v1.x)

* If using `openai>=1.0.0`, the correct call is:

```python
client = openai.OpenAI(api_key=your_key)
response = client.chat.completions.create(...)
```

* For `openai<1.0`, continue using `openai.ChatCompletion.create(...)`

---

## 📃 License

MIT License
